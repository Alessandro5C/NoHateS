{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTqhrPaSeE-z"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL1iFjECh3_6"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers -qq\n",
        "# !pip install sentencepiece -qq\n",
        "# !pip install tokenizer -qq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-pzooQXh5S7"
      },
      "source": [
        "##Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b_f63qOMVaA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkoUEM5LMVaB"
      },
      "outputs": [],
      "source": [
        "def to_df(x, y):\n",
        "    d = {\"text\": x, \"label\": y}\n",
        "    return pd.DataFrame(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgQOYQ6AMVaB",
        "outputId": "7d656ff7-1647-4ff3-ec59-f3156e58c15e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\anti-disc\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from itertools import chain\n",
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "from nlpaug.util import Action\n",
        "\n",
        "\n",
        "alpha_common_error = 0.10\n",
        "alpha_common_error_char = 0.05\n",
        "aug1_OCR = nac.OcrAug(aug_word_p=alpha_common_error)\n",
        "aug2_Rins = nac.RandomCharAug(action=\"insert\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug3_Rsub = nac.RandomCharAug(action=\"substitute\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug4_Rswa = nac.RandomCharAug(action=\"swap\", aug_word_p=alpha_common_error,aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char) #\n",
        "aug5_Rdel = nac.RandomCharAug(action=\"delete\", aug_word_p=alpha_common_error, aug_char_min=1, aug_char_max=1, aug_char_p=alpha_common_error_char)\n",
        "aug6_Kb = nac.KeyboardAug(aug_word_p=alpha_common_error)\n",
        "aug7_Split = naw.SplitAug(aug_p=alpha_common_error)\n",
        "\n",
        "\n",
        "def text2augment(text, m):\n",
        "    output = [text, ]\n",
        "\n",
        "    temp = random.sample(range(0, 7), m - 1)\n",
        "\n",
        "    if 0 in temp:\n",
        "        output.append( *aug1_OCR.augment(text))\n",
        "    if 1 in temp:\n",
        "        output.append( *aug2_Rins.augment(text))\n",
        "    if 2 in temp:\n",
        "        output.append( *aug3_Rsub.augment(text))\n",
        "    if 3 in temp:\n",
        "        output.append( *aug4_Rswa.augment(text))\n",
        "    if 4 in temp:\n",
        "        output.append( *aug5_Rdel.augment(text))\n",
        "    if 5 in temp:\n",
        "        output.append( *aug6_Kb.augment(text))\n",
        "    if 6 in temp:\n",
        "        output.append( *aug7_Split.augment(text))\n",
        "\n",
        "    return output\n",
        "\n",
        "\n",
        "def aug_replicate(y_labels):\n",
        "    return list(chain(* [[y]*(2 if y == 0 else 4) for y in y_labels] ))\n",
        "\n",
        "def aug_text(x_text, y_labels):\n",
        "    x_text = [ text2augment(x, 2 if y == 0 else 4) for x, y in zip(x_text, y_labels)]\n",
        "    return pd.Series(list(chain(*x_text)), index=None)\n",
        "\n",
        "def split_3_aug(df, test_size=0.2, valid_size=0.2):\n",
        "    _df = df.copy().sample(frac=1).reset_index()\n",
        "    _df = _df[[\"text\", \"label\"]]\n",
        "\n",
        "    x = _df[\"text\"].copy()\n",
        "    y = _df[\"label\"].copy()\n",
        "    #split train-test\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, stratify=y)\n",
        "    # augment\n",
        "    # x_test = aug_text(x_test, y_test)\n",
        "    # y_test = aug_replicate(y_test)\n",
        "    # split train-valid\n",
        "    x, y = x_train, y_train\n",
        "    x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=valid_size, stratify=y)\n",
        "    # augment\n",
        "    x_train = aug_text(x_train, y_train)\n",
        "    y_train = aug_replicate(y_train)\n",
        "    x_valid = aug_text(x_valid, y_valid)\n",
        "    y_valid = aug_replicate(y_valid)\n",
        "\n",
        "    print(x_valid.shape)\n",
        "    print(\"DONE\")\n",
        "    print(len(y_valid))\n",
        "\n",
        "    print(x_train.shape)\n",
        "    print(\"DONE\")\n",
        "    print(len(y_train))\n",
        "\n",
        "    return to_df(x_train, y_train), to_df(x_valid, y_valid), to_df(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTMXPNE2W6NJ",
        "outputId": "148b98c1-7b2c-4066-a2f2-d0c356ff2e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5772,)\n",
            "DONE\n",
            "5772\n",
            "(23082,)\n",
            "DONE\n",
            "23082\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tname_data = \"./hsd_merge_cleaned_lowered\"\n",
        "data = pd.read_csv(f\"{tname_data}.csv\")\n",
        "\n",
        "train, valid, test = split_3_aug(data)\n",
        "\n",
        "X_train = train['text']\n",
        "y_train = train['label']\n",
        "\n",
        "X_valid = valid['text']\n",
        "y_valid = valid['label']\n",
        "\n",
        "X_test = test['text']\n",
        "y_test = test['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La-lPuGjCxbb"
      },
      "source": [
        "## Set Cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnuQNrQ5Cxi_",
        "outputId": "7362def3-6fad-4e21-c042-0aaec25c5496"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHV2PrVfiBLg"
      },
      "source": [
        "# Extract feature by using BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MreD1ev6AgXM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from glob import glob\n",
        "\n",
        "train_sentences = list(train['text'].values)\n",
        "train_labels = list(train['label'].values)\n",
        "\n",
        "valid_sentences = list(valid['text'].values)\n",
        "valid_labels = list(valid['label'].values)\n",
        "\n",
        "test_sentences = list(test['text'].values)\n",
        "test_labels = list(test['label'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNVMN4YPiNjp"
      },
      "source": [
        "Load tokenizer of BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI8SPqPcA8BS"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX5lBYCTD9bU"
      },
      "outputs": [],
      "source": [
        "# Encode train label\n",
        "\n",
        "from sklearn import preprocessing\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(train_labels)\n",
        "encoded_labels = le.transform(train_labels)\n",
        "encoded_test_labels = le.transform(valid_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9XdWNkpFBgH",
        "outputId": "d7cd1781-9749-4125-d5a8-f3a660a8f605"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\anti-disc\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  a mi no me gusta porque el escudo es en blanco y negro y los colores del escudo no son esos puto fútbol​ moderno\n",
            "Token IDs: tensor([    4,  1013,  1153,  1084,  1129,  2816,  1817,  1040, 11888,  1058,\n",
            "         1036,  5122,  1042,  5499,  1042,  1065,  8855,  1072, 11888,  1084,\n",
            "         1404,  2651, 11935,  5921, 11897,     5,     1,     1,     1,     1],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Tokens IDs tensor\n",
        "\n",
        "def encoder_generator(sentences,labels):\n",
        "\n",
        "    sent_index = []\n",
        "    input_ids = []\n",
        "    attention_masks =[]\n",
        "\n",
        "    for index,sent in enumerate(sentences):\n",
        "\n",
        "        sent_index.append(index)\n",
        "\n",
        "        encoded_dict = tokenizer.encode_plus(sent,\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=30,\n",
        "                                             pad_to_max_length=True,\n",
        "                                             truncation = True,\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors='pt')\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids,dim=0).cuda()\n",
        "    attention_masks = torch.cat(attention_masks,dim=0).cuda()\n",
        "    labels = torch.tensor(labels).cuda()\n",
        "    sent_index = torch.tensor(sent_index).cuda()\n",
        "\n",
        "    return sent_index,input_ids,attention_masks,labels\n",
        "\n",
        "train_sent_index,train_input_ids,train_attention_masks,train_encoded_label_tensors = encoder_generator(train_sentences,encoded_labels)\n",
        "valid_sent_index,valid_input_ids,valid_attention_masks,valid_encoded_label_tensors = encoder_generator(valid_sentences,encoded_test_labels)\n",
        "print('Original: ', train_sentences[0])\n",
        "print('Token IDs:', train_input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYbqZ7NMMWw",
        "outputId": "639ca3da-af50-4d20-ebdd-263bddc13249"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train data samples is 23082\n",
            "valid data samples is 5772\n"
          ]
        }
      ],
      "source": [
        "# Connvert train, dev input by using TensorDataset\n",
        "\n",
        "from torch.utils.data import TensorDataset,random_split\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids,train_attention_masks,train_encoded_label_tensors)\n",
        "valid_dataset = TensorDataset(valid_input_ids,valid_attention_masks,valid_encoded_label_tensors)\n",
        "\n",
        "print('train data samples is {}'.format(len(train_dataset)))\n",
        "print(\"valid data samples is {}\".format(len(valid_dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em9Q1v0BMZZX"
      },
      "outputs": [],
      "source": [
        "# Set cuda by using device\n",
        "\n",
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "bs=128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=bs)\n",
        "valid_data_loader = DataLoader(valid_dataset,\n",
        "                              sampler=RandomSampler(valid_dataset),\n",
        "                              batch_size=bs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEtD7kn4jbTl"
      },
      "source": [
        "Load model BETO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160,
          "referenced_widgets": [
            "92b478ab8c8e4a0daa999aad57e95ac3",
            "2bc8b1500a1c41bd807761a54bf916bb",
            "9ef62896ca1b43c18c1adf8a282ef398",
            "cc4bb9d6a8e948cba93d31d073ac03af",
            "a864f46b0bd545a7bd1e974c107e4ef8",
            "02e5d40f71764e9994ec9223756a8e69",
            "6d1c543f9c8e431582ea5bee80a1a1aa",
            "e94092c637004e37a98cbbc13bc8a8b9",
            "b9a4f2122c874921a99f81f72b49c8c1",
            "71cbdcbf71284cfd96b9ad5259f1c7c0",
            "26b3d8d6fde64d82ad49dc81b193275f"
          ]
        },
        "id": "sQiHRn2zMdIJ",
        "outputId": "c561baf0-dfa7-436b-bfab-ad0a0307ca74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading pytorch_model.bin: 100%|██████████| 440M/440M [02:31<00:00, 2.89MB/s] \n",
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "beto = AutoModel.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
        "beto = beto.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEv63LPpjkcK"
      },
      "source": [
        "# Build CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q44-J-QWMgKQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNNForNLP(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_classes, num_filters, filter_sizes):\n",
        "        super(CNNForNLP, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(embedding_dim, num_filters, filter_size)\n",
        "            for filter_size in filter_sizes\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
        "\n",
        "    def forward(self, x, _):\n",
        "        embedded = self.embedding(x)  # x: (batch_size, sequence_length)\n",
        "        embedded = embedded.permute(0, 2, 1)  # embedded: (batch_size, embedding_dim, sequence_length)\n",
        "        feature_maps = []\n",
        "        for conv in self.convs:\n",
        "            feature_map = torch.relu(conv(embedded))  # feature_map: (batch_size, num_filters, H)\n",
        "            pooled = torch.max(feature_map, dim=2)[0]  # pooled: (batch_size, num_filters)\n",
        "            feature_maps.append(pooled)\n",
        "        combined = torch.cat(feature_maps, dim=1)  # combined: (batch_size, len(filter_sizes) * num_filters)\n",
        "        combined = self.dropout(combined)\n",
        "        logits = self.fc(combined)  # logits: (batch_size, num_classes)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTo_bpEeMqgr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Definir los parámetros del modelo\n",
        "vocab_size = 31002#tamaño del vocabulario\n",
        "embedding_dim = 768 #Dimension de los vectores de embedding\n",
        "num_classes = 2 #numero de clases o categorias de clasificacion\n",
        "num_filters = 32  #numero de filtros convolucionales\n",
        "filter_sizes = [3]  #tamaño de los filtros convolucionales\n",
        "\n",
        "\n",
        "CNNmodel = CNNForNLP(vocab_size,embedding_dim,num_classes,num_filters,filter_sizes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8QAddNK0rMj",
        "outputId": "ebd45748-066b-44ed-a887-52798434647f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNNForNLP(\n",
            "  (embedding): Embedding(31002, 768)\n",
            "  (convs): ModuleList(\n",
            "    (0): Conv1d(768, 32, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Imprimir el modelo\n",
        "print(CNNmodel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITmi7WZDMsl6"
      },
      "outputs": [],
      "source": [
        "# Optimizer and criterion\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "model_parameters = list(CNNmodel.parameters())\n",
        "\n",
        "optimizer = optim.Adam(model_parameters,lr=2e-5,eps=1e-8)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyp8HhAxMvQH"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy per batch during train\n",
        "\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]]).cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrVcBEVoMxov"
      },
      "outputs": [],
      "source": [
        "# Def for training\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(model):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(train_data_loader):\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(b_input_ids,b_input_mask)\n",
        "\n",
        "        loss = criterion(predictions, b_labels)\n",
        "\n",
        "        acc = categorical_accuracy(predictions, b_labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(train_data_loader), epoch_acc / len(train_data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTQGFfnFMz-d"
      },
      "outputs": [],
      "source": [
        "# Class for predict label\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def predictions_labels(preds,labels):\n",
        "    pred = np.argmax(preds,axis=1).flatten()\n",
        "    label = labels.flatten()\n",
        "    return pred,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_4Y1RhlM17e"
      },
      "outputs": [],
      "source": [
        "# Evaluate loss, acc  and f1-macro\n",
        "\n",
        "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
        "def eval(model):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    total_predictions = []\n",
        "    total_true = []\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in tqdm(valid_data_loader):\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_input_mask = batch[1].to(device)\n",
        "            b_labels = batch[2].to(device)\n",
        "\n",
        "            predictions = model(b_input_ids,b_input_mask)\n",
        "\n",
        "            loss = criterion(predictions, b_labels)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            pred,true = predictions_labels(predictions,label_ids)\n",
        "\n",
        "            all_pred_labels.extend(pred)\n",
        "            all_true_labels.extend(true)\n",
        "\n",
        "    print(classification_report(all_pred_labels,all_true_labels))\n",
        "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
        "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
        "\n",
        "    avg_val_loss = epoch_loss/len(valid_data_loader)\n",
        "\n",
        "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICyenO-tM35S"
      },
      "outputs": [],
      "source": [
        "# Time for training\n",
        "\n",
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OrAOzamNC0e",
        "outputId": "caf37e15-8576-4cfd-94e0-74ab261577f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNNForNLP(\n",
              "  (embedding): Embedding(31002, 768)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(768, 32, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set device and gpu\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "CNNmodel.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbJBkClEkam2"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfHllZjgM5uw",
        "outputId": "102f286f-dad1-4a1b-f6f3-b9fbfedb9430"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:04<00:00, 38.36it/s] \n",
            "100%|██████████| 46/46 [00:00<00:00, 554.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.77      0.86      5657\n",
            "           1       0.06      0.71      0.11       115\n",
            "\n",
            "    accuracy                           0.76      5772\n",
            "   macro avg       0.53      0.74      0.49      5772\n",
            "weighted avg       0.97      0.76      0.85      5772\n",
            "\n",
            "accuracy = 0.76\n",
            "model saved\n",
            "Epoch: 01 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.670 | Train acc: 63.16%\n",
            "\t Val. Loss: 0.532 |  Val. acc: 76.46%\n",
            "\t Val. Loss: 0.532 |  Val. F1: 48.60%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 108.05it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 621.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5517\n",
            "           1       0.12      0.69      0.21       255\n",
            "\n",
            "    accuracy                           0.77      5772\n",
            "   macro avg       0.55      0.73      0.54      5772\n",
            "weighted avg       0.94      0.77      0.84      5772\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 02 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.596 | Train acc: 71.22%\n",
            "\t Val. Loss: 0.514 |  Val. acc: 77.25%\n",
            "\t Val. Loss: 0.514 |  Val. F1: 53.88%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 108.33it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 613.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5479\n",
            "           1       0.14      0.67      0.23       293\n",
            "\n",
            "    accuracy                           0.77      5772\n",
            "   macro avg       0.56      0.73      0.55      5772\n",
            "weighted avg       0.94      0.77      0.83      5772\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 03 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.566 | Train acc: 73.46%\n",
            "\t Val. Loss: 0.502 |  Val. acc: 77.36%\n",
            "\t Val. Loss: 0.502 |  Val. F1: 54.94%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 108.11it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 656.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5467\n",
            "           1       0.15      0.68      0.24       305\n",
            "\n",
            "    accuracy                           0.77      5772\n",
            "   macro avg       0.56      0.73      0.55      5772\n",
            "weighted avg       0.93      0.77      0.83      5772\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 04 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.549 | Train acc: 74.42%\n",
            "\t Val. Loss: 0.498 |  Val. acc: 77.46%\n",
            "\t Val. Loss: 0.498 |  Val. F1: 55.41%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 108.12it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 629.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5470\n",
            "           1       0.14      0.68      0.24       302\n",
            "\n",
            "    accuracy                           0.77      5772\n",
            "   macro avg       0.56      0.73      0.55      5772\n",
            "weighted avg       0.93      0.77      0.83      5772\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 05 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.537 | Train acc: 75.24%\n",
            "\t Val. Loss: 0.497 |  Val. acc: 77.44%\n",
            "\t Val. Loss: 0.497 |  Val. F1: 55.31%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 108.21it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 638.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5464\n",
            "           1       0.15      0.67      0.24       308\n",
            "\n",
            "    accuracy                           0.77      5772\n",
            "   macro avg       0.56      0.72      0.55      5772\n",
            "weighted avg       0.93      0.77      0.83      5772\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 06 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.523 | Train acc: 75.67%\n",
            "\t Val. Loss: 0.490 |  Val. acc: 77.41%\n",
            "\t Val. Loss: 0.490 |  Val. F1: 55.37%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 108.67it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 647.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5467\n",
            "           1       0.15      0.67      0.24       305\n",
            "\n",
            "    accuracy                           0.77      5772\n",
            "   macro avg       0.56      0.73      0.55      5772\n",
            "weighted avg       0.93      0.77      0.83      5772\n",
            "\n",
            "accuracy = 0.77\n",
            "model saved\n",
            "Epoch: 07 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.516 | Train acc: 76.26%\n",
            "\t Val. Loss: 0.484 |  Val. acc: 77.43%\n",
            "\t Val. Loss: 0.484 |  Val. F1: 55.34%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 108.41it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 597.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5453\n",
            "           1       0.15      0.67      0.25       319\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.56      0.73      0.56      5772\n",
            "weighted avg       0.93      0.78      0.83      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 08 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.504 | Train acc: 76.63%\n",
            "\t Val. Loss: 0.492 |  Val. acc: 77.53%\n",
            "\t Val. Loss: 0.492 |  Val. F1: 55.84%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 107.75it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 630.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5454\n",
            "           1       0.15      0.68      0.25       318\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.57      0.73      0.56      5772\n",
            "weighted avg       0.93      0.78      0.83      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 09 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.495 | Train acc: 77.19%\n",
            "\t Val. Loss: 0.480 |  Val. acc: 77.58%\n",
            "\t Val. Loss: 0.480 |  Val. F1: 55.92%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 106.78it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 621.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5457\n",
            "           1       0.15      0.68      0.25       315\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.56      0.73      0.56      5772\n",
            "weighted avg       0.93      0.78      0.83      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 10 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.485 | Train acc: 77.68%\n",
            "\t Val. Loss: 0.479 |  Val. acc: 77.56%\n",
            "\t Val. Loss: 0.479 |  Val. F1: 55.83%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 105.28it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 629.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5438\n",
            "           1       0.16      0.68      0.26       334\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.57      0.73      0.56      5772\n",
            "weighted avg       0.93      0.78      0.83      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 11 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.479 | Train acc: 77.70%\n",
            "\t Val. Loss: 0.470 |  Val. acc: 77.69%\n",
            "\t Val. Loss: 0.470 |  Val. F1: 56.46%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 105.27it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 629.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5436\n",
            "           1       0.16      0.69      0.26       336\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.57      0.74      0.57      5772\n",
            "weighted avg       0.93      0.78      0.83      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 12 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.472 | Train acc: 78.31%\n",
            "\t Val. Loss: 0.469 |  Val. acc: 77.79%\n",
            "\t Val. Loss: 0.469 |  Val. F1: 56.70%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 105.18it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 629.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.78      0.87      5429\n",
            "           1       0.17      0.70      0.27       343\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.57      0.74      0.57      5772\n",
            "weighted avg       0.93      0.78      0.83      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 13 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.464 | Train acc: 78.42%\n",
            "\t Val. Loss: 0.468 |  Val. acc: 77.98%\n",
            "\t Val. Loss: 0.468 |  Val. F1: 57.22%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 104.96it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 605.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87      5430\n",
            "           1       0.17      0.71      0.28       342\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.57      0.75      0.57      5772\n",
            "weighted avg       0.93      0.78      0.84      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 14 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.459 | Train acc: 79.05%\n",
            "\t Val. Loss: 0.465 |  Val. acc: 78.10%\n",
            "\t Val. Loss: 0.465 |  Val. F1: 57.43%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 104.87it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 621.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87      5424\n",
            "           1       0.18      0.72      0.29       348\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.58      0.75      0.58      5772\n",
            "weighted avg       0.93      0.78      0.84      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 15 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.448 | Train acc: 79.54%\n",
            "\t Val. Loss: 0.463 |  Val. acc: 78.27%\n",
            "\t Val. Loss: 0.463 |  Val. F1: 57.89%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 105.09it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 621.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87      5409\n",
            "           1       0.19      0.73      0.30       363\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.58      0.76      0.59      5772\n",
            "weighted avg       0.93      0.78      0.84      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 16 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.448 | Train acc: 79.55%\n",
            "\t Val. Loss: 0.463 |  Val. acc: 78.47%\n",
            "\t Val. Loss: 0.463 |  Val. F1: 58.55%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 102.90it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 636.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87      5407\n",
            "           1       0.19      0.73      0.30       365\n",
            "\n",
            "    accuracy                           0.78      5772\n",
            "   macro avg       0.58      0.76      0.59      5772\n",
            "weighted avg       0.93      0.78      0.84      5772\n",
            "\n",
            "accuracy = 0.78\n",
            "model saved\n",
            "Epoch: 17 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.441 | Train acc: 79.74%\n",
            "\t Val. Loss: 0.458 |  Val. acc: 78.47%\n",
            "\t Val. Loss: 0.458 |  Val. F1: 58.59%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 104.86it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 605.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87      5382\n",
            "           1       0.20      0.73      0.32       390\n",
            "\n",
            "    accuracy                           0.79      5772\n",
            "   macro avg       0.59      0.76      0.59      5772\n",
            "weighted avg       0.92      0.79      0.84      5772\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 18 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.434 | Train acc: 80.25%\n",
            "\t Val. Loss: 0.456 |  Val. acc: 78.69%\n",
            "\t Val. Loss: 0.456 |  Val. F1: 59.49%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 105.56it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 629.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87      5394\n",
            "           1       0.20      0.74      0.31       378\n",
            "\n",
            "    accuracy                           0.79      5772\n",
            "   macro avg       0.59      0.77      0.59      5772\n",
            "weighted avg       0.93      0.79      0.84      5772\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 19 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.431 | Train acc: 80.22%\n",
            "\t Val. Loss: 0.464 |  Val. acc: 78.76%\n",
            "\t Val. Loss: 0.464 |  Val. F1: 59.40%\n",
            "=============Epoch Ended==============\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 181/181 [00:01<00:00, 107.95it/s]\n",
            "100%|██████████| 46/46 [00:00<00:00, 647.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.79      0.87      5380\n",
            "           1       0.21      0.74      0.32       392\n",
            "\n",
            "    accuracy                           0.79      5772\n",
            "   macro avg       0.59      0.77      0.60      5772\n",
            "weighted avg       0.92      0.79      0.84      5772\n",
            "\n",
            "accuracy = 0.79\n",
            "model saved\n",
            "Epoch: 20 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.429 | Train acc: 80.32%\n",
            "\t Val. Loss: 0.451 |  Val. acc: 78.86%\n",
            "\t Val. Loss: 0.451 |  Val. F1: 59.85%\n",
            "=============Epoch Ended==============\n"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "\n",
        "best_macro_f1 = float('0')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loss,train_acc = train(CNNmodel)\n",
        "    valid_loss,valid_acc,macro_f1 = eval(CNNmodel)\n",
        "    end_time = time.time()\n",
        "\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if macro_f1 > best_macro_f1:\n",
        "        best_macro_f1 = macro_f1\n",
        "    torch.save(CNNmodel,'./cnn_model_part1_'+'task2a_2.pt')\n",
        "    print(\"model saved\")\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. acc: {valid_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. F1: {macro_f1*100:.2f}%')\n",
        "    print('=============Epoch Ended==============')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KyQlcVfnCWHw"
      },
      "outputs": [],
      "source": [
        "# Save BETO and CNN\n",
        "\n",
        "torch.save(CNNmodel,'module2_part1.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCzo5AKq8lka"
      },
      "source": [
        "## EVALUATING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftons15Hw8lB",
        "outputId": "f185beee-82cd-4f6c-c407-6620e8bb54aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNNForNLP(\n",
              "  (embedding): Embedding(31002, 768)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(768, 32, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load BETO and cnn\n",
        "\n",
        "import torch\n",
        "CNNmodel = torch.load(r'cnn_model_part1_task2a_2.pt')\n",
        "CNNmodel.eval()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6sFPdMFlPRp"
      },
      "source": [
        "Predict label from true label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U9Co-AvE_Ehq",
        "outputId": "f724487d-1ca6-4121-f1fa-36b65ed01adc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\envs\\anti-disc\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "100%|██████████| 25/25 [00:00<00:00, 532.42it/s]\n"
          ]
        }
      ],
      "source": [
        "test_sent_index, test_input_ids, test_attention_masks, test_encoded_label_tensors = encoder_generator(test_sentences,test_labels)\n",
        "test_dataset = TensorDataset(test_input_ids,test_attention_masks,test_encoded_label_tensors)\n",
        "\n",
        "test_data_loader = DataLoader(test_dataset,\n",
        "                              sampler=RandomSampler(test_dataset),\n",
        "                              batch_size=bs)\n",
        "\n",
        "all_pred_labels = []\n",
        "all_true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(test_data_loader):\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    predictions = CNNmodel(b_input_ids,b_input_mask)\n",
        "\n",
        "\n",
        "    predictions = predictions.detach().cpu().numpy()\n",
        "\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    pred, true = predictions_labels(predictions, label_ids)\n",
        "\n",
        "    all_pred_labels.extend(pred)\n",
        "    all_true_labels.extend(true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ESaLntjdAfYF",
        "outputId": "d214a8f1-fb2e-4d62-ac3e-fca7e5b48c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9725    0.8870    0.9278      2990\n",
            "           1     0.2318    0.5763    0.3306       177\n",
            "\n",
            "    accuracy                         0.8696      3167\n",
            "   macro avg     0.6022    0.7316    0.6292      3167\n",
            "weighted avg     0.9311    0.8696    0.8944      3167\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The final score in the test set (classification report)\n",
        "\n",
        "print(classification_report(all_pred_labels,all_true_labels, digits = 4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2zqXgAK1zy6Y",
        "outputId": "528aa6a4-c7e6-4179-a0e7-1d39095015ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2652,   75],\n",
              "       [ 338,  102]], dtype=int64)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Confusion matrix in thetest set\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(all_true_labels, all_pred_labels)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfLoBK10MVaH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02e5d40f71764e9994ec9223756a8e69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26b3d8d6fde64d82ad49dc81b193275f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bc8b1500a1c41bd807761a54bf916bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e5d40f71764e9994ec9223756a8e69",
            "placeholder": "​",
            "style": "IPY_MODEL_6d1c543f9c8e431582ea5bee80a1a1aa",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "6d1c543f9c8e431582ea5bee80a1a1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71cbdcbf71284cfd96b9ad5259f1c7c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b478ab8c8e4a0daa999aad57e95ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bc8b1500a1c41bd807761a54bf916bb",
              "IPY_MODEL_9ef62896ca1b43c18c1adf8a282ef398",
              "IPY_MODEL_cc4bb9d6a8e948cba93d31d073ac03af"
            ],
            "layout": "IPY_MODEL_a864f46b0bd545a7bd1e974c107e4ef8"
          }
        },
        "9ef62896ca1b43c18c1adf8a282ef398": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e94092c637004e37a98cbbc13bc8a8b9",
            "max": 439621341,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9a4f2122c874921a99f81f72b49c8c1",
            "value": 439621341
          }
        },
        "a864f46b0bd545a7bd1e974c107e4ef8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a4f2122c874921a99f81f72b49c8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc4bb9d6a8e948cba93d31d073ac03af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71cbdcbf71284cfd96b9ad5259f1c7c0",
            "placeholder": "​",
            "style": "IPY_MODEL_26b3d8d6fde64d82ad49dc81b193275f",
            "value": " 440M/440M [00:04&lt;00:00, 29.7MB/s]"
          }
        },
        "e94092c637004e37a98cbbc13bc8a8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}